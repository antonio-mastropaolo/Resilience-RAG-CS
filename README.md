	The recent surge in Large Language Models (LLMs) has catalyzed significant advancements across various fields, with software engineering being no exception. Among these advancements, Retrieval Augmented Generation (RAG) is a particularly-appealing one. RAG systems combine retrieval of artifacts from a local (e.g., domain-specific) knowledge-basewith a LLM-based generation. This helps generating solutions to problems for which the LLM is not specifically trained or fine-tuned.One risk RAG may have is that, if the knowledge-basecontains noisy data, the produced output can be erroneous too.
	This paper explores the resilience of RAG systems in the context of a software engineering task, specifically code summarization. We investigate what happens when RAG knowledge-basecontains various levels of data inconsistency/noisiness. We first assess the impact of inconsistent data to the retriever component implemented with two different techniques (BM25 or Transformer-based), and then the effect on the generator side, by leveraging  two state-of-the-art LLMs, CodeLlama and GPT-4. Our results show that, while Transformer-based retrieval methods generally outperform BM25 in terms of resilience, they struggle to maintain adherence to developer-written summaries as inconsistency levels in the knowledge-basefluctuate. On the generator side, both LLMs—CodeLlama and GPT-4—show resilience against varying levels of inconsistency, with CodeLlama displaying superior overall performance by guaranteeing that the generated code summaries are of higher quality. 